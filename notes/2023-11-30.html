

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>23. Neural Networks &#8212; Programming for Data Science at URI Fall 2023</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/course-admonitions.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notes/2023-11-30';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1. Assignment 1: Setup, Syllabus, and Review" href="../assignments/01-syllabus-install.html" />
    <link rel="prev" title="22. More text representations" href="2023-11-28.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/310_2021.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/310_2021.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    About this Book
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Syllabus</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/about.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../syllabus/tools.html">Tools and Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../syllabus/achievements.html">Data Science Achievements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../syllabus/grading.html">Grading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../syllabus/policies.html">Grading Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../syllabus/style.html">Course  Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../syllabus/uri_resources.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../syllabus/uri_statements.html">General URI Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../syllabus/communication.html">Communications &amp; Office Hours</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="2023-09-07.html">1. Welcome &amp; What is Data Science</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-09-12.html">2. Iterables and Pandas Data Frames</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-09-14.html">3. DataFrames from other sources</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-09-19.html">4. Exploratory Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-09-21.html">5. Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-09-26.html">6. Tidy Data and Structural Repairs</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-09-28.html">7. Reparing values</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-10-03.html">8. Merging Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-10-05.html">9. Web Scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-10-12.html">10. Evaluating ML Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-10-17.html">11. Intro to ML &amp; Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-10-19.html">12. Understanding Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-10-24.html">13. Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-10-26.html">14. Clustering Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-10-31.html">15. Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-11-02.html">16. Interpretting Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-11-07.html">17. Cross Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-11-09.html">18. Model Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-11-14.html">19. Model Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-11-16.html">20. Learning Curves and more Model Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-11-21.html">21. Representing Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="2023-11-28.html">22. More text representations</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">23. Neural Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../assignments/01-syllabus-install.html">1. Assignment 1: Setup, Syllabus, and Review</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/02-python-access.html">2. Assignment 2: Practicing Python and Accessing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/03-eda.html">3. Assignment 3: Exploratory Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/04-prepare.html">4. Assignment 4: Cleaning Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/05-construct.html">5. Assignment 5: Constructing Datasets and Using Databases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/06-evaluate.html">6. Assignment 6: Auditing Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/07-classification.html">7. Assignment 7</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/08-clustering.html">8. Assignment 8: Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/09-regression.html">9. Assignment 9: Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/10-optimize.html">10. Assignment 10: Tuning Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/11-compare.html">11. Assignment 11: Model Comparison</a></li>
<li class="toctree-l1"><a class="reference internal" href="../assignments/12-fake-news.html">12. Assignment 12: Fake News</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Portfolio</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../portfolio/index.html">Portfolio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../portfolio/formatting.html">Formatting Tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="../portfolio/check1ideas.html">Portfolio Check 1 Ideas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../portfolio/check2ideas.html">Check 2 Ideas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../portfolio/check3ideas.html">Check 3 Ideas</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/syllabus.html">Syllabus and Grading FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/github.html">Git and GitHub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/debugging.html">Code Errors</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../resources/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/python.html">References on Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/cheatsheet.html">Cheatsheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/datasets.html">Data Sources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/tips.html">General Tips and Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/learning.html">How to Study in this class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/gettinghelp.html">Getting Help with Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/terminal.html">Terminals and Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/organization.html">Getting Organized for class</a></li>
<li class="toctree-l1"><a class="reference external" href="https://rhodyprog4ds.github.io/BrownFall20/letters/">Advice from FA2020 Students</a></li>
<li class="toctree-l1"><a class="reference external" href="https://rhodyprog4ds.github.io/BrownFall21/letters/">Advice from FA2021 Students</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/rhodyprog4ds/BrownFall23" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/rhodyprog4ds/BrownFall23/edit/main/notes/2023-11-30.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/rhodyprog4ds/BrownFall23/issues/new?title=Issue%20on%20page%20%2Fnotes/2023-11-30.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notes/2023-11-30.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#admin">23.1. Admin</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-neural-network">23.2. What is a Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nn-in-sklearn">23.3. NN in Sklearn</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-nn-to-mlp">23.4. Comparing nn to mlp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network-predictions">23.5. Neural Network Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#another-way-to-replicate">23.6. Another way to replicate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-more-complicated-example">23.7. A more complicated example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#questions">23.8. Questions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#are-there-neural-networks-wherein-each-layer-does-a-different-type-of-transformation-such-as-logistic-or-identity">23.8.1. Are there neural networks wherein each layer does a different type of transformation, such as logistic or identity?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-the-benefits-of-neural-networks-compared-to-machine-learning">23.8.2. What are the benefits of neural networks compared to machine learning?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-the-larger-contributing-in-advancements-in-deep-learning-hardware-or-software">23.8.3. What is the larger contributing in advancements in deep learning - hardware or software?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#are-there-any-other-visualizations-of-neural-networks-such-as-images-articles-videos-that-would-be-good-for-introductions-i-would-like-some-that-do-go-into-some-of-the-math-behind-how-it-works">23.8.4. Are there any other visualizations of neural networks such as images,articles,videos that would be good for introductions? I would like some that do go into some of the math behind how it works.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#are-you-able-to-keep-training-data-from-a-previous-session-with-deep-learning">23.8.5. Are you able to keep training data from a previous session with deep learning?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-other-functions-can-we-use-instead-of-explit-sigmoid">23.8.6. What other functions can we use instead of explit (sigmoid)?</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="neural-networks">
<h1><span class="section-number">23. </span>Neural Networks<a class="headerlink" href="#neural-networks" title="Permalink to this headline">#</a></h1>
<section id="admin">
<h2><span class="section-number">23.1. </span>Admin<a class="headerlink" href="#admin" title="Permalink to this headline">#</a></h2>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>We will have 2 speakers to wrap up the semester:</p>
<ul class="simple">
<li><p>12/7: <a class="reference external" href="https://www.linkedin.com/in/nirmal-keshava-0180012/">Nirmal Keshava</a></p></li>
<li><p>12/12: <a class="reference external" href="https://www.linkedin.com/in/tiffanysithiphone/">Tiffany Sithiphone</a></p></li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>P3 is due 12/4 unless you got a note from me saying that I saw your P2, but I have not graded it yet.</p>
</div>
</section>
<section id="what-is-a-neural-network">
<h2><span class="section-number">23.2. </span>What is a Neural Network<a class="headerlink" href="#what-is-a-neural-network" title="Permalink to this headline">#</a></h2>
<p>We started thinking about machine learning with the idea that the basic idea is
that we assume that our target variable (<span class="math notranslate nohighlight">\(y_i\)</span>) is related to the features <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span>
by some function (for sample <span class="math notranslate nohighlight">\(i\)</span>):</p>
<div class="math notranslate nohighlight">
\[ y_i =f(\mathbf{x}_i;\theta)\]</div>
<p>But we don’t know that function exactly, so we assume a type (a decision
tree, a boundary for SVM, a probability distribution) that has some parameters
<span class="math notranslate nohighlight">\(\theta\)</span> and then use a machine
learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> to estimate the parameters for <span class="math notranslate nohighlight">\(f\)</span>.  In the
decision tree the parameters are the thresholds to compare to, in the GaussianNB the parameters are the mean and variance, in SVM it’s the support vectors that define the margin.</p>
<div class="math notranslate nohighlight">
\[\theta = \mathcal{A}(X,y) \]</div>
<p>That we can use to test on our test data:</p>
<div class="math notranslate nohighlight">
\[ \hat{y}_i = f(x_i;\theta) \]</div>
<p>A neural net allows us to not assume a specific form for <span class="math notranslate nohighlight">\(f\)</span> first, it does
universal function approximation.  For one hidden layer and a binary classification problem:</p>
<div class="math notranslate nohighlight">
\[f(x) = W_2g(W_1^T x +b_1) + b_2 \]</div>
<p>where the function <span class="math notranslate nohighlight">\(g\)</span> is called the activation function. We approximate some
unknown, complicated function <span class="math notranslate nohighlight">\(f\)</span> by taking a weighted sum of all of the inputs,
and passing those through another, known function, <span class="math notranslate nohighlight">\(g\)</span>.</p>
<p>The learning step involves finding the weights and biases (or coeffificents and intercepts). It does so by finding the weights that minimize some loss function on the data:</p>
<div class="math notranslate nohighlight">
\[ min_{W_1,W_2,b_1,b_2} \ell(f(x),y)\]</div>
<p>where the loss function <span class="math notranslate nohighlight">\(\ell\)</span> describes the “cost” of errors. For example it might be simple does the prediction match or more complex like how close it is.</p>
</section>
<section id="nn-in-sklearn">
<h2><span class="section-number">23.3. </span>NN in Sklearn<a class="headerlink" href="#nn-in-sklearn" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">expit</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;colorblind&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will use the digits dataset again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
<span class="n">digits_X</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span>
<span class="n">digits_y</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">digits_X</span><span class="p">,</span><span class="n">digits_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],
       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],
       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],
       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],
       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],
       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],
       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],
       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">sklearn</span></code> provides a neural network by the name <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
  <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">),</span>
  <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
  <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
  <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
  <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We specify:</p>
<ul class="simple">
<li><p>the number of neurons in each hidden layer</p></li>
<li><p>the number of steps in the optimizaiton to do</p></li>
<li><p>the solver is the algorithm used to find the parameters</p></li>
<li><p>for it to output interim info as it works</p></li>
<li><p>fix the random state so we all use the same initialization</p></li>
<li><p>the initial learning rate (how fast to change parameter values while searching)</p></li>
</ul>
<p>Then we use it just like we use all other sklearn estimators.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =         1210     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  9.40391D+00    |proj g|=  7.25043D+00

At iterate    1    f=  8.27245D+00    |proj g|=  7.33800D+00

At iterate    2    f=  3.34677D+00    |proj g|=  2.06114D+00

At iterate    3    f=  2.40712D+00    |proj g|=  4.15820D-01

At iterate    4    f=  2.29097D+00    |proj g|=  2.54784D-01

At iterate    5    f=  2.13910D+00    |proj g|=  2.77693D-01

At iterate    6    f=  2.01280D+00    |proj g|=  2.89541D-01

At iterate    7    f=  1.72508D+00    |proj g|=  1.01612D+00

At iterate    8    f=  1.65968D+00    |proj g|=  6.66645D-01

At iterate    9    f=  1.54443D+00    |proj g|=  3.46057D-01

At iterate   10    f=  1.48358D+00    |proj g|=  3.27554D-01

At iterate   11    f=  1.41171D+00    |proj g|=  2.85272D-01

At iterate   12    f=  1.23456D+00    |proj g|=  2.73880D-01

At iterate   13    f=  1.17939D+00    |proj g|=  9.80296D-01

At iterate   14    f=  1.10448D+00    |proj g|=  2.47666D-01

At iterate   15    f=  1.07770D+00    |proj g|=  1.56778D-01

At iterate   16    f=  1.01970D+00    |proj g|=  4.87342D-01

At iterate   17    f=  9.78778D-01    |proj g|=  4.73049D-01

At iterate   18    f=  9.26638D-01    |proj g|=  2.03028D-01

At iterate   19    f=  8.76803D-01    |proj g|=  2.02681D-01

At iterate   20    f=  8.27339D-01    |proj g|=  4.31792D-01

At iterate   21    f=  7.68534D-01    |proj g|=  4.63986D-01

At iterate   22    f=  7.41465D-01    |proj g|=  2.76490D-01

At iterate   23    f=  7.26458D-01    |proj g|=  1.33532D-01

At iterate   24    f=  7.04734D-01    |proj g|=  2.71124D-01

At iterate   25    f=  6.75241D-01    |proj g|=  3.87226D-01

At iterate   26    f=  6.42634D-01    |proj g|=  1.70220D-01

At iterate   27    f=  6.10969D-01    |proj g|=  4.69950D-01

At iterate   28    f=  5.79995D-01    |proj g|=  3.94014D-01

At iterate   29    f=  5.48411D-01    |proj g|=  3.69173D-01

At iterate   30    f=  5.12923D-01    |proj g|=  4.76438D-01

At iterate   31    f=  4.79564D-01    |proj g|=  1.44522D-01

At iterate   32    f=  4.60730D-01    |proj g|=  2.33291D-01

At iterate   33    f=  4.45106D-01    |proj g|=  1.08693D-01

At iterate   34    f=  4.18274D-01    |proj g|=  4.12410D-01

At iterate   35    f=  4.00504D-01    |proj g|=  2.83697D-01

At iterate   36    f=  3.80351D-01    |proj g|=  1.02830D-01

At iterate   37    f=  3.56491D-01    |proj g|=  1.35042D-01

At iterate   38    f=  3.36476D-01    |proj g|=  2.00188D-01

At iterate   39    f=  3.23757D-01    |proj g|=  5.98133D-01

At iterate   40    f=  3.06646D-01    |proj g|=  1.81957D-01

At iterate   41    f=  3.01625D-01    |proj g|=  9.67825D-02

At iterate   42    f=  2.93063D-01    |proj g|=  5.24219D-02

At iterate   43    f=  2.75103D-01    |proj g|=  1.50304D-01

At iterate   44    f=  2.63878D-01    |proj g|=  2.86373D-01

At iterate   45    f=  2.49254D-01    |proj g|=  9.18127D-02

At iterate   46    f=  2.42015D-01    |proj g|=  7.12341D-02

At iterate   47    f=  2.37280D-01    |proj g|=  8.79295D-02

At iterate   48    f=  2.26173D-01    |proj g|=  1.09953D-01

At iterate   49    f=  2.24209D-01    |proj g|=  2.51448D-01

At iterate   50    f=  2.15664D-01    |proj g|=  6.69376D-02

At iterate   51    f=  2.11250D-01    |proj g|=  3.67292D-02

At iterate   52    f=  2.04076D-01    |proj g|=  9.44192D-02

At iterate   53    f=  1.95835D-01    |proj g|=  1.56955D-01

At iterate   54    f=  1.92756D-01    |proj g|=  1.88308D-01

At iterate   55    f=  1.85303D-01    |proj g|=  3.87196D-02

At iterate   56    f=  1.82619D-01    |proj g|=  6.74958D-02

At iterate   57    f=  1.76912D-01    |proj g|=  1.13160D-01

At iterate   58    f=  1.72024D-01    |proj g|=  1.20778D-01

At iterate   59    f=  1.67015D-01    |proj g|=  3.51875D-02

At iterate   60    f=  1.63303D-01    |proj g|=  7.03249D-02

At iterate   61    f=  1.60459D-01    |proj g|=  7.64248D-02

At iterate   62    f=  1.55862D-01    |proj g|=  3.82312D-02

At iterate   63    f=  1.55102D-01    |proj g|=  1.72817D-01

At iterate   64    f=  1.52024D-01    |proj g|=  7.05391D-02

At iterate   65    f=  1.50135D-01    |proj g|=  3.15599D-02

At iterate   66    f=  1.47715D-01    |proj g|=  7.04390D-02

At iterate   67    f=  1.45089D-01    |proj g|=  8.60698D-02

At iterate   68    f=  1.41113D-01    |proj g|=  6.55423D-02

At iterate   69    f=  1.38332D-01    |proj g|=  9.10053D-02

At iterate   70    f=  1.35825D-01    |proj g|=  4.06173D-02

At iterate   71    f=  1.32371D-01    |proj g|=  6.01693D-02

At iterate   72    f=  1.30045D-01    |proj g|=  6.52722D-02

At iterate   73    f=  1.27703D-01    |proj g|=  3.93364D-02

At iterate   74    f=  1.26034D-01    |proj g|=  4.53927D-02

At iterate   75    f=  1.21125D-01    |proj g|=  6.18286D-02

At iterate   76    f=  1.18190D-01    |proj g|=  5.74455D-02

At iterate   77    f=  1.15610D-01    |proj g|=  2.68655D-02

At iterate   78    f=  1.13272D-01    |proj g|=  2.64427D-02

At iterate   79    f=  1.11289D-01    |proj g|=  4.45123D-02

At iterate   80    f=  1.09776D-01    |proj g|=  7.84298D-02

At iterate   81    f=  1.08314D-01    |proj g|=  4.59670D-02

At iterate   82    f=  1.06905D-01    |proj g|=  3.35440D-02

At iterate   83    f=  1.05637D-01    |proj g|=  4.30825D-02

At iterate   84    f=  1.03096D-01    |proj g|=  6.32154D-02

At iterate   85    f=  1.00656D-01    |proj g|=  7.66120D-02

At iterate   86    f=  9.92600D-02    |proj g|=  3.20820D-02

At iterate   87    f=  9.78231D-02    |proj g|=  3.00969D-02

At iterate   88    f=  9.65266D-02    |proj g|=  4.26389D-02

At iterate   89    f=  9.52018D-02    |proj g|=  4.81253D-02

At iterate   90    f=  9.34543D-02    |proj g|=  4.91024D-02

At iterate   91    f=  9.18389D-02    |proj g|=  2.82063D-02

At iterate   92    f=  9.05110D-02    |proj g|=  2.93229D-02

At iterate   93    f=  8.87077D-02    |proj g|=  3.85490D-02

At iterate   94    f=  8.56893D-02    |proj g|=  7.31366D-02

At iterate   95    f=  8.44146D-02    |proj g|=  2.11226D-02

At iterate   96    f=  8.39004D-02    |proj g|=  1.98654D-02

At iterate   97    f=  8.22351D-02    |proj g|=  2.69318D-02

At iterate   98    f=  8.12596D-02    |proj g|=  4.30663D-02

At iterate   99    f=  7.98023D-02    |proj g|=  7.89129D-02

At iterate  100    f=  7.83888D-02    |proj g|=  2.82801D-02

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
 1210    100    104      1     0     0   2.828D-02   7.839D-02
  F =   7.8388839659254791E-002

STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> This problem is unconstrained.
/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result(&quot;lbfgs&quot;, opt_res, self.max_iter)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9155555555555556
</pre></div>
</div>
</div>
</div>
</section>
<section id="comparing-nn-to-mlp">
<h2><span class="section-number">23.4. </span>Comparing nn to mlp<a class="headerlink" href="#comparing-nn-to-mlp" title="Permalink to this headline">#</a></h2>
<p>Letsw fit an SVM</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm_clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">svm_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svm_clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9933333333333333
</pre></div>
</div>
</div>
</div>
<p>Here we get better performance with this, but we can alos check the complexity to compare them.</p>
<p>We can see how many support vectors that this had to store.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm_clf</span><span class="o">.</span><span class="n">support_vectors_</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(691, 64)
</pre></div>
</div>
</div>
</div>
<p>and then multiply all together to get the total numbers stored:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">svm_clf</span><span class="o">.</span><span class="n">support_vectors_</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>44224
</pre></div>
</div>
</div>
</div>
<p>for the MLP, we’ll use the weights:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">mlp</span><span class="o">.</span><span class="n">coefs_</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1184
</pre></div>
</div>
</div>
</div>
<p>We can see these shapes are determined by the data and the size of the hidden that we specifies and the number of classes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">mlp</span><span class="o">.</span><span class="n">coefs_</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[64, 16], [16, 10]]
</pre></div>
</div>
</div>
</div>
<p>In this case we have:</p>
<ul class="simple">
<li><p>64 features (8x8 pixels)</p></li>
<li><p>16 hidden layer neurons</p></li>
<li><p>10 classes</p></li>
</ul>
<p>we have 10 neurons in the output layer because each output neuron is related to one class. Each output neuron relates to one class, so for it to be one that class is predicted and the others are 0 for training.  At prediction time, we say the highest value one is the ones that we read as the prediction.  We interpret the outpus as the probability that the sample belongs to each class.</p>
</section>
<section id="neural-network-predictions">
<h2><span class="section-number">23.5. </span>Neural Network Predictions<a class="headerlink" href="#neural-network-predictions" title="Permalink to this headline">#</a></h2>
<p>We’ll start with some toy data for classification.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
             <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">hue</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: &gt;
</pre></div>
</div>
<img alt="../_images/af7cacba3bff1698dadbe7bc98b428213c86c0583a58eed0995b7ed753700d58.png" src="../_images/af7cacba3bff1698dadbe7bc98b428213c86c0583a58eed0995b7ed753700d58.png" />
</div>
</div>
<p>it’s two simple features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
 <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># 1 hidden layer, 1 aritficial neuron</span>
 <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># maximum 100 interations in optimization</span>
 <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="c1"># regularization</span>
 <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span> <span class="c1">#optimization algorithm  </span>
 <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># how much detail to print</span>
 <span class="n">activation</span><span class="o">=</span> <span class="s1">&#39;identity&#39;</span> <span class="c1"># how to transform the hidden layer beofore passing it to the next layer</span>
<span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =            5     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  8.02331D-01    |proj g|=  5.09797D-01

At iterate    1    f=  3.69278D-01    |proj g|=  2.51074D-01

At iterate    2    f=  1.50478D-01    |proj g|=  8.61969D-02

At iterate    3    f=  9.54380D-02    |proj g|=  4.96103D-02

At iterate    4    f=  7.22965D-02    |proj g|=  2.57521D-02

At iterate    5    f=  6.07288D-02    |proj g|=  1.61252D-02

At iterate    6    f=  5.62998D-02    |proj g|=  2.90812D-02

At iterate    7    f=  5.20850D-02    |proj g|=  1.02569D-02

At iterate    8    f=  4.90884D-02    |proj g|=  2.76414D-03

At iterate    9    f=  4.82053D-02    |proj g|=  3.08878D-03

At iterate   10    f=  4.79256D-02    |proj g|=  7.83441D-04

At iterate   11    f=  4.79062D-02    |proj g|=  9.58952D-05

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments ex
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> This problem is unconstrained.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>plored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
    5     11     12      1     0     0   9.590D-05   4.791D-02
  F =   4.7906199858129855E-002

CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL            
</pre></div>
</div>
</div>
</div>
<p>this does very well</p>
<p>We can see that this network has one activation for the hidden layers</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">activation</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;identity&#39;
</pre></div>
</div>
</div>
</div>
<p>and a different one for the output layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">out_activation_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;logistic&#39;
</pre></div>
</div>
</div>
</div>
<p>The sigmoid function looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_logistic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y_logistic</span> <span class="o">=</span> <span class="n">expit</span><span class="p">(</span><span class="n">x_logistic</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_logistic</span><span class="p">,</span><span class="n">y_logistic</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x7f3b18cffe50&gt;]
</pre></div>
</div>
<img alt="../_images/3f54361fdb8264dc3ec0bbf139c48946663d1d0d82053dad3decf22f990a2c30.png" src="../_images/3f54361fdb8264dc3ec0bbf139c48946663d1d0d82053dad3decf22f990a2c30.png" />
</div>
</div>
<p>The object also has coefficients</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[array([[ 4.7401027 ],
        [-0.13595873]]),
 array([[2.76359301]])]
</pre></div>
</div>
</div>
</div>
<p>and intercepts as attributes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[array([1.8565197]), array([0.54548524])]
</pre></div>
</div>
</div>
</div>
<p>To test this, we will make a new sample, the point (-1,2)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<p>The hidden neuron in this case does the following calculation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-3.15550046]])
</pre></div>
</div>
</div>
</div>
<p>then the output neuron takes that as input and uses its own weights, and the sigmoid function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">expit</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span><span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.00028152]])
</pre></div>
</div>
</div>
</div>
<p>This calculates the probability the output is 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[9.99718482e-01, 2.81517668e-04]])
</pre></div>
</div>
</div>
</div>
<p>This method predicts the probabity of both 0 and 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span><span class="o">-</span> <span class="n">expit</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span><span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.99971848]])
</pre></div>
</div>
</div>
</div>
<p>and we can confirm that we have replicated the function of the predictions for the neural network.</p>
</section>
<section id="another-way-to-replicate">
<h2><span class="section-number">23.6. </span>Another way to replicate<a class="headerlink" href="#another-way-to-replicate" title="Permalink to this headline">#</a></h2>
<p>We can consider a neuron like a tempalte function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">aritificial_neuron_template</span><span class="p">(</span><span class="n">activation</span><span class="p">,</span><span class="n">weights</span><span class="p">,</span><span class="n">bias</span><span class="p">,</span><span class="n">inputs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    simple artificial neuron</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    activation : function</span>
<span class="sd">    activation function of the neuron</span>
<span class="sd">    weights : numpy aray</span>
<span class="sd">    wights for summing inputs one per input</span>
<span class="sd">    bias: numpy array</span>
<span class="sd">    bias term added to the weighted sum</span>
<span class="sd">    inputs : numpy array</span>
<span class="sd">    input to the neuron, must be same size as weights</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="n">activation</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">weights</span><span class="p">)</span> <span class="o">+</span><span class="n">bias</span><span class="p">)</span>

<span class="c1"># two common activation functions</span>
<span class="n">identity_activation</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span>
<span class="n">logistic_activation</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">expit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that this function takes in:</p>
<ul class="simple">
<li><p>inputs (features)</p></li>
<li><p>weights</p></li>
<li><p>bias</p></li>
<li><p>activation function</p></li>
</ul>
<p>We also define two activation functions.</p>
<p>When we set up to train a neural network, we tell the learning algorithm what activation function to use and then it learns the weights.</p>
<p>This is equivalent to our neural network above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_neuron</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">identity_activation</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">output_neuron</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">h</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">expit</span><span class="p">,</span><span class="n">clf</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">clf</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">h</span><span class="p">)</span>

<span class="n">output_neuron</span><span class="p">(</span><span class="n">hidden_neuron</span><span class="p">(</span><span class="n">pt</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.00028152]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-more-complicated-example">
<h2><span class="section-number">23.7. </span>A more complicated example<a class="headerlink" href="#a-more-complicated-example" title="Permalink to this headline">#</a></h2>
<p>This time we’ll make similar data with 4 features instead of 2  and we’ll set up a test point <code class="docutils literal notranslate"><span class="pre">pt_4d</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_informative</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                          <span class="n">random_state</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">pt_4d</span> <span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mf">1.5</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">clf_4d</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
  <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
  <span class="n">max_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
  <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
  <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
  <span class="n">activation</span><span class="o">=</span> <span class="s1">&#39;identity&#39;</span>
<span class="p">)</span>

<span class="n">clf_4d</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">clf_4d</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =            7     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  6.79422D-01    |proj g|=  1.34972D-01

At iterate    1    f=  6.65530D-01    |proj g|=  7.00821D-02

At iterate    2    f=  6.33021D-01    |proj g|=  1.51025D-01

At iterate    3    f=  5.71749D-01    |proj g|=  4.71791D-01

At iterate    4    f=  5.23813D-01    |proj g|=  8.81233D-02

At iterate    5    f=  5.12066D-01    |proj g|=  6.99840D-02

At iterate    6    f=  4.85893D-01    |proj g|=  1.02977D-01

At iterate    7    f=  4.76397D-01    |proj g|=  8.22339D-02

At iterate    8    f=  4.73793D-01    |proj g|=  1.85566D-02

At iterate    9    f=  4.73386D-01    |proj g|=  1.91639D-02

At iterate   10    f=  4.72211D-01    |proj g|=  2.99922D-02

At iterate   11    f=  4.68997D-01    |proj g|=  6.37131D-02

At iterate   12    f=  4.59284D-01    |proj g|=  5.50552D-02

At iterate   13    f=  4.54418D-01    |proj g|=  3.66207D-02

At iterate   14    f=  4.47827D-01    |proj g|=  5.20024D-02

At iterate   15    f=  4.36195D-01    |proj g|=  1.98149D-02

At iterate   16    f=  4.35486D-01    |proj g|=  6.59890D-03

At iterate   17    f=  4.35104D-01    |proj g|=  8.46506D-03

At iterate   18    f=  4.34937D-01    |proj g|=  8.32958D-03

At iterate   19    f=  4.34911D-01    |proj g|=  1.75302D-02

At iterate   20    f=  4.34713D-01    |proj g|=  8.86609D-03

At iterate   21    f=  4.34664D-01    |proj g|=  1.25730D-03

At iterate   22    f=  4.34663D-01    |proj g|=  5.49466D-05

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
    7     22     27      1     0     0   5.495D-05   4.347D-01
  F =  0.43466279898568450     

CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL            
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> This problem is unconstrained.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.84
</pre></div>
</div>
</div>
</div>
<p>this does well again</p>
<p>we can see the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x0&#39;</span><span class="p">,</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span><span class="s1">&#39;x2&#39;</span><span class="p">,</span><span class="s1">&#39;x3&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x7f3b18c617f0&gt;
</pre></div>
</div>
<img alt="../_images/5a3507a0f7604736a85d5290b63567be81c52c7fc3003ea0d1d826c0e7cc3c5a.png" src="../_images/5a3507a0f7604736a85d5290b63567be81c52c7fc3003ea0d1d826c0e7cc3c5a.png" />
</div>
</div>
<p>we can do it again with our template function by defining two functions: one for the hidden neuron and one for output, then the prediction</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_neuron_4d</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">identity_activation</span><span class="p">,</span>
                             <span class="n">clf_4d</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">clf_4d</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">output_neuron_4d</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                             <span class="n">clf_4d</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">clf_4d</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>


<span class="n">output_neuron_4d</span><span class="p">(</span><span class="n">hidden_neuron_4d</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.95358788],
       [0.85324909]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_4d</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.04641212, 0.95358788],
       [0.14675091, 0.85324909]])
</pre></div>
</div>
</div>
</div>
<p>and confirm it’s correct.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pt_4d_2</span> <span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="o">-</span><span class="mf">.5</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mf">1.5</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mf">.5</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">output_neuron_4d</span><span class="p">(</span><span class="n">hidden_neuron_4d</span><span class="p">(</span><span class="n">pt_4d_2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.99145594],
       [0.90639784]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_4d</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt_4d_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.00854406, 0.99145594],
       [0.09360216, 0.90639784]])
</pre></div>
</div>
</div>
</div>
<p>We can build up what we need for a 4 hidden neuron MLP too.  First we’ll train the MLP</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_4d_4h</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span>
  <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
  <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
  <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
  <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
  <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;logistic&#39;</span>
<span class="p">)</span>

<span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =           25     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  6.86993D-01    |proj g|=  5.15503D-02

At iterate    1    f=  6.71843D-01    |proj g|=  4.81291D-02

At iterate    2    f=  6.11201D-01    |proj g|=  4.38953D-02

At iterate    3    f=  5.40478D-01    |proj g|=  5.29556D-02

At iterate    4    f=  4.96079D-01    |proj g|=  6.22516D-02

At iterate    5    f=  4.69397D-01    |proj g|=  3.20348D-02

At iterate    6    f=  4.47412D-01    |proj g|=  5.25604D-02

At iterate    7    f=  4.25078D-01    |proj g|=  1.81292D-02

At iterate    8    f=  4.14300D-01    |proj g|=  2.21372D-02

At iterate    9    f=  3.13232D-01    |proj g|=  5.29668D-02

At iterate   10    f=  2.55893D-01    |proj g|=  4.88671D-02

At iterate   11    f=  2.01154D-01    |proj g|=  5.60794D-02

At iterate   12    f=  1.86222D-01    |proj g|=  2.29334D-02

At iterate   13    f=  1.78364D-01    |proj g|=  1.70823D-02

At iterate   14    f=  1.56030D-01    |proj g|=  1.22533D-02

At iterate   15    f=  1.38981D-01    |proj g|=  1.06683D-02

At iterate   16    f=  1.28551D-01    |proj g|=  8.28843D-03

At iterate   17    f=  1.22909D-01    |proj g|=  1.02772D-02

At iterate   18    f=  1.19455D-01    |proj g|=  5.37004D-03

At iterate   19    f=  1.14854D-01    |proj g|=  2.63923D-03

At iterate   20    f=  1.12021D-01    |proj g|=  5.46547D-03

At iterate   21    f=  1.08211D-01    |proj g|=  9.03422D-03

At iterate   22    f=  1.02509D-01    |proj g|=  8.47140D-03

At iterate   23    f=  9.82937D-02    |proj g|=  5.87285D-03

At iterate   24    f=  9.40374D-02    |proj g|=  2.77348D-03

At iterate   25    f=  9.25076D-02    |proj g|=  2.91121D-03

At iterate   26    f=  8.98174D-02    |proj g|=  7.12924D-03

At iterate   27    f=  8.82365D-02    |proj g|=  3.38542D-03

At iterate   28    f=  8.68338D-02    |proj g|=  2.37871D-03

At iterate   29    f=  8.48995D-02    |proj g|=  4.22036D-03

At iterate   30    f=  8.42852D-02    |proj g|=  5.21892D-03

At iterate   31    f=  8.31786D-02    |proj g|=  6.55434D-03

At iterate   32    f=  8.06873D-02    |proj g|=  1.16838D-02

At iterate   33    f=  7.61894D-02    |proj g|=  7.89277D-03

At iterate   34    f=  7.21708D-02    |proj g|=  2.28003D-02

At iterate   35    f=  7.02870D-02    |proj g|=  5.65231D-03

At iterate   36    f=  6.91244D-02    |proj g|=  5.01037D-03

At iterate   37    f=  6.68795D-02    |proj g|=  3.15619D-03

At iterate   38    f=  6.55812D-02    |proj g|=  7.81240D-03

At iterate   39    f=  6.35301D-02    |proj g|=  7.53858D-03

At iterate   40    f=  6.14805D-02    |proj g|=  1.05793D-02

At iterate   41    f=  5.80625D-02    |proj g|=  2.07321D-03

At iterate   42    f=  5.75816D-02    |proj g|=  1.08850D-03

At iterate   43    f=  5.69555D-02    |proj g|=  8.84371D-04

At iterate   44    f=  5.66800D-02    |proj g|=  6.40567D-04

At iterate   45    f=  5.65004D-02    |proj g|=  7.28330D-04

At iterate   46    f=  5.63871D-02    |proj g|=  5.62131D-04

At iterate   47    f=  5.63435D-02    |proj g|=  9.96171D-04

At iterate   48    f=  5.62820D-02    |proj g|=  4.88708D-04

At iterate   49    f=  5.62423D-02    |proj g|=  4.04656D-04

At iterate   50    f=  5.61874D-02    |proj g|=  3.80582D-04

At iterate   51    f=  5.61425D-02    |proj g|=  3.05703D-04

At iterate   52    f=  5.61022D-02    |proj g|=  2.04803D-04

At iterate   53    f=  5.60590D-02    |proj g|=  6.19325D-04

At iterate   54    f=  5.59989D-02    |proj g|=  3.51337D-04

At iterate   55    f=  5.58804D-02    |proj g|=  3.00464D-04

At iterate   56    f=  5.57899D-02    |proj g|=  5.29091D-04

At iterate   57    f=  5.56706D-02    |proj g|=  6.46040D-04

At iterate   58    f=  5.56216D-02    |proj g|=  1.36581D-03

At iterate   59    f=  5.55088D-02    |proj g|=  2.60926D-04

At iterate   60    f=  5.54751D-02    |proj g|=  2.01477D-04

At iterate   61    f=  5.54198D-02    |proj g|=  4.32818D-04

At iterate   62    f=  5.53570D-02    |proj g|=  3.67092D-04

At iterate   63    f=  5.52725D-02    |proj g|=  3.64889D-04

At iterate   64    f=  5.52607D-02    |proj g|=  4.42936D-04

At iterate   65    f=  5.52043D-02    |proj g|=  3.53198D-04

At iterate   66    f=  5.51655D-02    |proj g|=  4.64748D-04

At iterate   67    f=  5.51210D-02    |proj g|=  1.78778D-04

At iterate   68    f=  5.50443D-02    |proj g|=  2.36651D-04

At iterate   69    f=  5.49911D-02    |proj g|=  3.03305D-04

At iterate   70    f=  5.49714D-02    |proj g|=  1.97655D-04

At iterate   71    f=  5.49425D-02    |proj g|=  1.03619D-04

At iterate   72    f=  5.49227D-02    |proj g|=  7.89413D-05

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
   25     72     83      1     0     0   7.894D-05   5.492D-02
  F =   5.4922664996025897E-002

CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL            
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> This problem is unconstrained.
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=4, max_iter=500,
              solver=&#x27;lbfgs&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">MLPClassifier</label><div class="sk-toggleable__content"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=4, max_iter=500,
              solver=&#x27;lbfgs&#x27;, verbose=10)</pre></div></div></div></div></div></div></div>
</div>
<p>Then use our function to build up the predictions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_neuron_4d_h0</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                             <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">hidden_neuron_4d_h1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                             <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">hidden_neuron_4d_h2</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                             <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">2</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">hidden_neuron_4d_h3</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                             <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span><span class="mi">3</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">3</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
<span class="n">output_neuron_4d_4h</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">aritificial_neuron_template</span><span class="p">(</span><span class="n">logistic_activation</span><span class="p">,</span>
                             <span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">intercepts_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>and finally call it all togther</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output_neuron_4d_4h</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">hidden_neuron_4d_h0</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">),</span>
         <span class="n">hidden_neuron_4d_h1</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">),</span>
         <span class="n">hidden_neuron_4d_h2</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">),</span>
         <span class="n">hidden_neuron_4d_h3</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.99946891],
       [0.928926  ]])
</pre></div>
</div>
</div>
</div>
<p>and compare with the MLP’s own predications</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_4d_4h</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">pt_4d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[5.31087115e-04, 9.99468913e-01],
       [7.10740021e-02, 9.28925998e-01]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="questions">
<h2><span class="section-number">23.8. </span>Questions<a class="headerlink" href="#questions" title="Permalink to this headline">#</a></h2>
<section id="are-there-neural-networks-wherein-each-layer-does-a-different-type-of-transformation-such-as-logistic-or-identity">
<h3><span class="section-number">23.8.1. </span>Are there neural networks wherein each layer does a different type of transformation, such as logistic or identity?<a class="headerlink" href="#are-there-neural-networks-wherein-each-layer-does-a-different-type-of-transformation-such-as-logistic-or-identity" title="Permalink to this headline">#</a></h3>
<p>There are different types of layers and some are defined by activations, others are more complex calculations in other ways.</p>
</section>
<section id="what-are-the-benefits-of-neural-networks-compared-to-machine-learning">
<h3><span class="section-number">23.8.2. </span>What are the benefits of neural networks compared to machine learning?<a class="headerlink" href="#what-are-the-benefits-of-neural-networks-compared-to-machine-learning" title="Permalink to this headline">#</a></h3>
<p>Neural networks are one type of machine learning model.</p>
</section>
<section id="what-is-the-larger-contributing-in-advancements-in-deep-learning-hardware-or-software">
<h3><span class="section-number">23.8.3. </span>What is the larger contributing in advancements in deep learning - hardware or software?<a class="headerlink" href="#what-is-the-larger-contributing-in-advancements-in-deep-learning-hardware-or-software" title="Permalink to this headline">#</a></h3>
<p>Hardware advances were essential for</p>
</section>
<section id="are-there-any-other-visualizations-of-neural-networks-such-as-images-articles-videos-that-would-be-good-for-introductions-i-would-like-some-that-do-go-into-some-of-the-math-behind-how-it-works">
<h3><span class="section-number">23.8.4. </span>Are there any other visualizations of neural networks such as images,articles,videos that would be good for introductions? I would like some that do go into some of the math behind how it works.<a class="headerlink" href="#are-there-any-other-visualizations-of-neural-networks-such-as-images-articles-videos-that-would-be-good-for-introductions-i-would-like-some-that-do-go-into-some-of-the-math-behind-how-it-works" title="Permalink to this headline">#</a></h3>
<p>This <a class="reference external" href="https://www.deeplearningbook.org/">free textbook</a> is a good source by leaders in the feild.</p>
</section>
<section id="are-you-able-to-keep-training-data-from-a-previous-session-with-deep-learning">
<h3><span class="section-number">23.8.5. </span>Are you able to keep training data from a previous session with deep learning?<a class="headerlink" href="#are-you-able-to-keep-training-data-from-a-previous-session-with-deep-learning" title="Permalink to this headline">#</a></h3>
<p>For any machine learning algorithm you can save the object or serialize the parameters to a file and then load them back in.</p>
<p>For deep learning you can save the weight matrices and you can also then reinstantiate the object.</p>
<p><a class="reference external" href="https://huggingface.co/models">Hugging face</a> contains pretrained models.</p>
</section>
<section id="what-other-functions-can-we-use-instead-of-explit-sigmoid">
<h3><span class="section-number">23.8.6. </span>What other functions can we use instead of explit (sigmoid)?<a class="headerlink" href="#what-other-functions-can-we-use-instead-of-explit-sigmoid" title="Permalink to this headline">#</a></h3>
<p>The most common other one is RELU, we’ll see more about that next week.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="2023-11-28.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">22. </span>More text representations</p>
      </div>
    </a>
    <a class="right-next"
       href="../assignments/01-syllabus-install.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1. </span>Assignment 1: Setup, Syllabus, and Review</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#admin">23.1. Admin</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-neural-network">23.2. What is a Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nn-in-sklearn">23.3. NN in Sklearn</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-nn-to-mlp">23.4. Comparing nn to mlp</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network-predictions">23.5. Neural Network Predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#another-way-to-replicate">23.6. Another way to replicate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-more-complicated-example">23.7. A more complicated example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#questions">23.8. Questions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#are-there-neural-networks-wherein-each-layer-does-a-different-type-of-transformation-such-as-logistic-or-identity">23.8.1. Are there neural networks wherein each layer does a different type of transformation, such as logistic or identity?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-the-benefits-of-neural-networks-compared-to-machine-learning">23.8.2. What are the benefits of neural networks compared to machine learning?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-the-larger-contributing-in-advancements-in-deep-learning-hardware-or-software">23.8.3. What is the larger contributing in advancements in deep learning - hardware or software?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#are-there-any-other-visualizations-of-neural-networks-such-as-images-articles-videos-that-would-be-good-for-introductions-i-would-like-some-that-do-go-into-some-of-the-math-behind-how-it-works">23.8.4. Are there any other visualizations of neural networks such as images,articles,videos that would be good for introductions? I would like some that do go into some of the math behind how it works.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#are-you-able-to-keep-training-data-from-a-previous-session-with-deep-learning">23.8.5. Are you able to keep training data from a previous session with deep learning?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-other-functions-can-we-use-instead-of-explit-sigmoid">23.8.6. What other functions can we use instead of explit (sigmoid)?</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Professor Sarah M Brown
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>