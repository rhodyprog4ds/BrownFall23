---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.15.1
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Understanding Classification


```{warning}
I am goign to fill this in later. There is some on prismia though. 
```

```{code-cell} ipython3
import pandas as pd
import seaborn as sns
from sklearn import tree
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
sns.set_theme(palette='colorblind') # this improves contrast

from sklearn.metrics import confusion_matrix, classification_report
```

```{code-cell} ipython3
iris_df = sns.load_dataset('iris')
```

```{code-cell} ipython3
# dataset vars:
# 'petal_width',  'sepal_length','species', 'sepal_width','petal_length',
feature_vars = ['petal_width',  'sepal_length', 'sepal_width','petal_length']
target_var = 'species'
X_train, X_test, y_train, y_test = train_test_split(iris_df[feature_vars],
                                                    iris_df[target_var],random_state=3)
```

```{code-cell} ipython3
sns.pairplot(data = iris_df, hue='species')
```

```{code-cell} ipython3
gnb = GaussianNB()
```

```{code-cell} ipython3
gnb.fit(X_train,y_train)
```

```{code-cell} ipython3
y_pred = gnb.predict(X_test)
```

```{code-cell} ipython3
gnb.score(X_test,y_test)
```

```{code-cell} ipython3
print(classification_report(y_test,y_pred))
```

```{code-cell} ipython3
y_test.value_counts()
```

```{code-cell} ipython3
confusion_matrix(y_test,y_pred)
```

```{code-cell} ipython3
gnb.__dict__
```

```{code-cell} ipython3
import numpy as np
```

```{code-cell} ipython3
N = 50
gnb_df = pd.DataFrame(np.concatenate([np.random.multivariate_normal(th, sig*np.eye(4),N)
                 for th, sig in zip(gnb.theta_,gnb.var_)]),
                 columns = gnb.feature_names_in_)
gnb_df['species'] = [ci for cl in [[c]*N for c in gnb.classes_] for ci in cl]
sns.pairplot(data =gnb_df, hue='species')
```

```{code-cell} ipython3
gnb.predict_proba(X_test)
```

```{code-cell} ipython3
# make the probabilities into a dataframe labeled with classes & make the index a separate column
prob_df = pd.DataFrame(data = gnb.predict_proba(X_test), columns = gnb.classes_ ).reset_index()
# add the predictions
prob_df['predicted_species'] = y_pred
prob_df['true_species'] = y_test.values
# for plotting, make a column that combines the index & prediction
pred_text = lambda r: str( r['index']) + ',' + r['predicted_species']
prob_df['i,pred'] = prob_df.apply(pred_text,axis=1)
# same for ground truth
true_text = lambda r: str( r['index']) + ',' + r['true_species']
prob_df['correct'] = prob_df['predicted_species'] == prob_df['true_species']
# a dd a column for which are correct
prob_df['i,true'] = prob_df.apply(true_text,axis=1)
prob_df_melted = prob_df.melt(id_vars =[ 'index', 'predicted_species','true_species','i,pred','i,true','correct'],value_vars = gnb.classes_,
                             var_name = target_var, value_name = 'probability')
prob_df_melted.head()
```

```{code-cell} ipython3
# plot a bar graph for each point labeled with the prediction
sns.catplot(data =prob_df_melted, x = 'species', y='probability' ,col ='i,true',
            col_wrap=5,kind='bar')
```

```{code-cell} ipython3
corner_data = 'https://raw.githubusercontent.com/rhodyprog4ds/06-naive-bayes/f425ba121cc0c4dd8bcaa7ebb2ff0b40b0b03bff/data/dataset6.csv'
df6= pd.read_csv(corner_data,usecols=[1,2,3])
```

```{code-cell} ipython3
df6.head(1)
```

```{code-cell} ipython3
sns.pairplot(data=df6, hue='char', hue_order=['A','B'])
```

```{code-cell} ipython3
X_train, X_test, y_train, y_test = train_test_split(df6[['x0','x1']],df6['char'], random_state=4)
```

```{code-cell} ipython3
gnb_corners = GaussianNB()
gnb_corners.fit(X_train,y_train)
gnb_corners.score(X_test, y_test)
```

```{code-cell} ipython3
N = 100
gnb_df = pd.DataFrame(np.concatenate([np.random.multivariate_normal(th, sig*np.eye(2),N)
         for th, sig in zip(gnb_corners.theta_,gnb_corners.var_)]),
         columns = ['x0','x1'])
gnb_df['char'] = [ci for cl in [[c]*N for c in gnb_corners.classes_] for ci in cl]

sns.pairplot(data =gnb_df, hue='char',hue_order=['A','B'])
```

```{code-cell} ipython3
df6_pred = X_test.copy()
df6_pred['pred'] = gnb_corners.predict(X_test)
```

```{code-cell} ipython3
sns.pairplot(data =df6_pred, hue ='pred', hue_order =['A','B'])
```

```{code-cell} ipython3
dt = tree.DecisionTreeClassifier()
```

```{code-cell} ipython3
dt.fit(X_train,y_train)
```

```{code-cell} ipython3
dt.score(X_test,y_test)
```

```{code-cell} ipython3
plt.figure(figsize=(15,20))
tree.plot_tree(dt, rounded =True, class_names = ['A','B'],
      proportion=True, filled =True, impurity=False,fontsize=10);
```

```{code-cell} ipython3

```

## Questions After Class

### When should you start focusing on portfolio check 2? 

When you get P1 feedback

### when will p1 check be graded?

As soon as possible. 


### why not use a decision tree initially for the iris dataset?

To teach the Gaussian Naive Bayes classifier, because learning different types of classifiers helps you understand the concept better. 

### Are there any popular machine learning models that use decision trees?

Yes, a lot of medical appilcations do, because since they are easy to understand, it is easier for healthcare providers to trust them. 


### Do predictive algorithms have pros and cons? Or is there a standard?

Each algorithm has different properties and strengths and weaknesses.  Some are more popular than others, but they all do have weaknesses. 

### Different kinds of trees/charts, analyze what they mean and how to translate those

### is it possible after training the model to add more data to it ?

The models we will see in class, no.  However, there is a thing called "online learning" that involves getting more data on a regular basis to improve its performance.  
