---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.15.1
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Learning Curves and more Model Comparison


```{code-cell} ipython3
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pandas as pd
from sklearn import datasets
from sklearn import cluster
from sklearn import svm
from sklearn import tree
# import the whole model selection module
from sklearn import model_selection
sns.set_theme(palette='colorblind')
```


````{margin}
```{admonition} Further Reading

If you struggled to understand this code excerpt to fill in the comments, some generic strategies to understand code may help, beyond applying what we have covered in class.

[The Programmer's brain](https://www.manning.com/books/the-programmers-brain)
is an overview of how brains work, as applied to programming, written for working
developers. This means that it assumes you know most CS concepts and at least two programming languages. If you don't there may be some parts that do not make sense to you, but the general ideas should still make sense.
The author is a professor who researchers how people learn
programming and how to effectively teach it.


This book is available for free online, including an audio version of the first chapter.

**I strongly recommend this if you have trouble remembering things**
```
````

```{code-cell} ipython3
# load and split the data
iris_X, iris_y = datasets.load_iris(return_X_y=True)
iris_X_train, iris_X_test, iris_y_train, iris_y_test = model_selection.train_test_split(
  iris_X,iris_y, test_size =.2)


# create dt,
dt = tree.DecisionTreeClassifier()

# set param grid 
params_dt = {'criterion':['gini','entropy'],
       'max_depth':[2,3,4,5,6],
    'min_samples_leaf':list(range(2,20,2))}
# create optimizer
dt_opt = model_selection.GridSearchCV(dt,params_dt,cv=10)


# optimize the dt parameters
dt_opt.fit(iris_X_train,iris_y_train)

# store the results in a dataframe
dt_df = pd.DataFrame(dt_opt.cv_results_)


# create svm, its parameter grid and optimizer
svm_clf = svm.SVC()
param_grid = {'kernel':['linear','rbf'], 'C':[.5, .75,1,2,5,7, 10]}
svm_opt = model_selection.GridSearchCV(svm_clf,param_grid,cv=10)

# optmize the svm put the CV results in a dataframe
svm_opt.fit(iris_X_train,iris_y_train)
sv_df = pd.DataFrame(svm_opt.cv_results_)
```

So we have redone some familiar code.  We have found the optimal parameters for best accuracy for two different classifiers, SVM and Decision tree on our data. 



This is extra detail we did not do in class for time reasons

We can  use EDA to understand how the score varied across all of the parameter settings we tried.

```{code-cell} ipython3
sv_df['mean_test_score'].describe()
```

```{code-cell} ipython3
dt_df['mean_test_score'].describe()
```

From this we see that in both cases the standard deviation (std) is really
low. This tells us that the parameter changes didn't impact the performance
much.  Combined with the overall high accuracy this tells us that the data
is probably really easy to classify.  If the performance had been uniformly
bad, it might have instead told us that we did not try a wide enough range
of parameters.

To confirm how many parameter settings we have used we can check a couple different ways. First, above in the count of the describe.

We can also calculate directly from the parameter grids before we even do the fit.


```{code-cell} ipython3
description_vars = ['param_C', 'param_kernel', 'params',]
vars_to_plot = ['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time']
svm_time = sv_df.melt(id_vars= description_vars,
           value_vars=vars_to_plot)
sns.lmplot(data=sv_df, x='mean_fit_time',y='mean_test_score',
     hue='param_kernel',fit_reg=False)
```

## How does the timing vary?
Let's dig in and see which one is better. 

```{code-cell} ipython3
sv_df.head(1)
```


```{code-cell} ipython3
svm_time = sv_df.melt(id_vars=['param_C', 'param_kernel', 'params',],
                      value_vars=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time'])
sns.lmplot(data=sv_df, x='mean_fit_time',y='mean_test_score',
          hue='param_kernel',fit_reg=False)
```

```{code-cell} ipython3
svm_time.head()
```

```{code-cell} ipython3
sns.catplot(data= svm_time, x='param_kernel',y='value',hue='variable')
```

## How does training impact our model?


Now we can create the learning curve.


```{code-cell} ipython3
train_sizes, train_scores, test_scores, fit_times, score_times = model_selection.learning_curve(svm_opt.best_estimator_,iris_X_train, iris_y_train,
                              train_sizes= [.4,.5,.6,.8],return_times=True)
```


It returns the list of the counts for each training size (we input percentages and it returns counts)
```{code-cell} ipython3
[train_sizes, train_scores, test_scores, fit_times, score_times]
```


We can use our skills in transforming data to make it easier to exmine just a subset of the scores.
````{margin}
```{hint}
This is *one* thing we can analyze, but there are others. To earn prepare on assignment 11,  manipulate your results a different way.
```
````
```{code-cell} ipython3
train_scores.mean(axis=1)
```

We can stack these into a list, with the means for the cross validated values
```{code-cell} ipython3
[train_sizes, train_scores.mean(axis=1), test_scores.mean(axis=1),
                                fit_times.mean(axis=1), score_times.mean(axis=1)]
```

then cast it to a numpy array
```{code-cell} ipython3
np.asarray([train_sizes, train_scores.mean(axis=1), test_scores.mean(axis=1),
                                fit_times.mean(axis=1), score_times.mean(axis=1)]).T
```

Then we can put it all into a DataFrame so that we can plot it. 
```{code-cell} ipython3
curve_df = pd.DataFrame(data = np.asarray([train_sizes, train_scores.mean(axis=1), test_scores.mean(axis=1),
                                fit_times.mean(axis=1), score_times.mean(axis=1)]).T,
                    columns = ['train_sizes', 'train_scores', 'test_scores', 'fit_times', 'score_times'])
curve_df.head()
```

we will melt it to make it tidy and can work better with seaborn plotting functions. 

```{code-cell} ipython3
curve_df_tall = curve_df.melt(id_vars='train_sizes',)
sns.relplot(data =curve_df_tall,x='train_sizes',y ='value',hue ='variable' )
```

We can see here that the training score and test score are basically the same. This means we're doing about as well as we cana at learning the a generalizable model and we probably hav enough data for this task.  




## Digits Dataset
Today, we'll load a new dataset and use the default sklearn data structure for datasets.  We get back the default data stucture when we use a `load_` function without any parameters at all.



```{code-cell} ipython3
digits = datasets.load_digits()
```

This shows us that the type is defined by sklearn and they called it `bunch`:
```{code-cell} ipython3
type(digits)
```

We can print it out to begin exploring it.
```{code-cell} ipython3
digits
```

We note that it has key value pairs, and that the last one is called `DESCR` and is text that describes the data.  If we send that to the print function it will be formatted more readably.

```{code-cell} ipython3
print(digits['DESCR'])
```


This tells us that we are going to be predicting what digit (0,1,2,3,4,5,6,7,8, or 9) is in the image.

To get an idea of what the images look like, we can use `matshow` which is short for matrix show. It takes a 2D matrix and plots it as a grayscale image. To get the actual color bar, we use the matplotlib `plt.gray()`.  
````{margin}
```{admonition} Try it yourself
Try using matshow without `plt.gray()`. How is it different?  What might alternatives do?  What other code in this notebook influences how plots look?
```
```{tip}
Removing a line from an excerpt of code can help you see hat that line did and learn more about how each piece work.
```
````

```{code-cell} ipython3
plt.gray()
plt.matshow(digits.images[8])
```

and we can pick another one
```{code-cell} ipython3
plt.gray()
plt.matshow(digits.images[198])
```

For easier ML, we will reload it differently: 



```{code-cell} ipython3
digits_X, digits_y = datasets.load_digits(return_X_y=True)
```

This has one row for each sample and has reshaped the 8x8 image into a 64 length vector. So we have one 'feature' for each pixel in the images.


```{code-cell} ipython3
digits_X.shape
```

Now we can train a model and generate a learning curve. 

```{code-cell} ipython3
svm_clf_digits = svm.SVC()
train_sizes, train_scores, test_scores, fit_times, score_times = model_selection.learning_curve(
                            svm_clf_digits,digits_X, digits_y,
                              train_sizes= [.1,.2,.3,.4,.5,.6,.8,.9, .95,.97,.99],return_times=True)
```

and we will make this into a DataFrame the same way as with the iris data above. 



```{code-cell} ipython3
digits_curve_df = pd.DataFrame(data = np.asarray([train_sizes, train_scores.mean(axis=1), test_scores.mean(axis=1),
                                fit_times.mean(axis=1), score_times.mean(axis=1)]).T,
                    columns = ['train_sizes', 'train_scores', 'test_scores', 'fit_times', 'score_times'])
```

```{code-cell} ipython3
digits_curve_df
```

```{code-cell} ipython3
digits_curve_df_tall = digits_curve_df.melt(id_vars = 'train_sizes', value_vars=[ 'train_scores', 'test_scores'])
sns.relplot(data =digits_curve_df_tall, x = 'train_sizes',y='value',hue='variable',)
```

This larger gap shows that a different model or maybe more data could help us learn better.  Th good news is that we are probably not overfitting, overfitting would occur when the training accuracy still improves but the test accuracy goes down. 

## Decision Tree with digits data

```{code-cell} ipython3
dt_digits = tree.DecisionTreeClassifier()
train_sizes, train_scores, test_scores, fit_times, score_times = model_selection.learning_curve(
                            dt_digits,digits_X, digits_y,
                              train_sizes= [.1,.2,.3,.4,.5,.6,.8,.9, .95,.97,.99],return_times=True)
```

```{code-cell} ipython3
train_scores.shape
```

```{code-cell} ipython3
digits_curve_df_dt = pd.DataFrame(data = np.asarray([train_sizes, train_scores.mean(axis=1), test_scores.mean(axis=1),
                                fit_times.mean(axis=1), score_times.mean(axis=1)]).T,
                    columns = ['train_sizes', 'train_scores', 'test_scores', 'fit_times', 'score_times'])
```

```{code-cell} ipython3
digits_curve_df_dt
```

```{code-cell} ipython3
digits_curve_df_tall_dt = digits_curve_df_dt.melt(id_vars = 'train_sizes', value_vars=[ 'train_scores', 'test_scores'])
sns.relplot(data =digits_curve_df_tall_dt, x = 'train_sizes',y='value',hue='variable',)
```

This one does much worse that above. 

<!-- ## Why does the score time get longer? -->




```{important}
I spent time also giving help and answering questions for A11.
```
