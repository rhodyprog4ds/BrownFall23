#### **python-level1**
  
_python code that mostly runs, occasional pep8 adherance_ 


- [ ] use of control structures
- [ ] callable functions
- [ ] correct calls to functions
- [ ] correct use of variables
- [ ] use of logical operators


#### **python-level2**
  
_python code that reliably runs, frequent pep8 adherance_ 


- [ ] descriptive variable names
- [ ] pythonic loops
- [ ] effective use of return vs side effects in functions
- [ ] correct, effective use of builtin python iterable types (lists & dictionaries)


#### **python-level3**
  
_reliable, efficient, pythonic code that consistently adheres to pep8_ 


- [ ] pep8 adherant variable, file, class, and function names
- [ ] effective use of multi-paradigm abilities for efficiency gains
- [ ] easy to read code that adheres to readability over other rules


#### **process-level1**
  
_Identify basic components of data science_ 


- [ ] identify component disciplines
- [ ] idenitfy phases


#### **process-level2**
  
_Describe and define each stage of the data science process_ 


- [ ] correctly defines stages
- [ ] identifies stages in use
- [ ] describes general goals as well as a specific processes


#### **process-level3**
  
_Compare different ways that data science can facilitate decision making_ 


- [ ] describes exceptions to process and iteration in process
- [ ] connects choices at one phase to impacts in other phases
- [ ] connects data science steps to real world decisions


#### **access-level1**
  
_load data from at least one format; identify the most common data formats_ 


- [ ] use at least one pandas `read_` function correctly
- [ ] name common types
- [ ] describe the structure of common types


#### **access-level2**
  
_Load data for processing from the most common formats; Compare and constrast most common formats_ 


- [ ] load data from at least two of (.csv, .tsv, .dat, database, .json)
- [ ] describe advantages and disadvantages of most commone types
- [ ] descive how most common types are different


#### **access-level3**
  
_access data from both common and uncommon formats and identify best practices for formats in different contexts_ 


- [ ] load data from at least 1 uncommon format
- [ ] describe when one format is better than another


#### **construct-level1**
  
_identify what should happen to merge datasets or when they can be merged_ 


- [ ] identify what the structure of a merged dataset should be (size, shape, columns)
- [ ] idenitfy when datasets can or cannot be merged


#### **construct-level2**
  
_apply basic merges_ 


- [ ] use 3 different types of merges
- [ ] choose the right type of merge for realistic scenarios


#### **construct-level3**
  
_merge data that is not automatically aligned_ 


- [ ] manipulate data to make it mergable
- [ ] identify how to combine data from many sources to answer a question
- [ ] implement stesp to combine data from multiple sources


#### **summarize-level1**
  
_Describe the shape and structure of a dataset in basic terms_ 


- [ ] use attributes to produce a description of a dataset
- [ ] display parts of a dataset


#### **summarize-level2**
  
_compute and interpret summary standard statistics of a whole dataset and grouped data_ 


- [ ] compute descriptive statistics on whole datasets
- [ ] apply individual statistics to datasets
- [ ] group data by a categorical variable for analysis
- [ ] apply split-apply-combine paradigm to analyze data
- [ ] interprete statistics on whole datasets
- [ ] interpret statistics on subsets of data


#### **summarize-level3**
  
_Compute and interpret various summary statistics of subsets of data_ 


- [ ] produce custom aggregation tables to summarize datasets
- [ ] compute multivariate summary statistics by grouping
- [ ] compute custom cacluations on datasets


#### **visualize-level1**
  
_identify plot types, generate basic plots from pandas_ 


- [ ] generate at least two types of plots with pandas
- [ ] identify plot types by name
- [ ] interpret basic information from plots


#### **visualize-level2**
  
_generate multiple plot types with complete labeling with pandas and seaborn_ 


- [ ] generate at least 3 types of plots
- [ ] use correct, complete, legible labeling on plots
- [ ] plot using both pandas and seaborn
- [ ] interpret multiple types of plots to draw conclusions


#### **visualize-level3**
  
_generate complex plots with pandas and plotting libraries and customize with matplotlib or additional parameters_ 


- [ ] use at least two libraries to plot
- [ ] generate figures with subplots
- [ ] customize the display of a plot to be publication ready
- [ ] interpret plot types and explain them for novices
- [ ] choose appopriate plot types to convey information
- [ ] explain why plotting common best practices are effective


#### **prepare-level1**
  
_identify if data is or is not ready for analysis, potential problems with data_ 


- [ ] identify problems in a dataset
- [ ] anticipate how potential data setups will interfere with analysis
- [ ] describe the structure of tidy data
- [ ] label data as tidy or not


#### **prepare-level2**
  
_apply data reshaping, cleaning, and filtering as directed_ 


- [ ] reshape data to be analyzable as directed
- [ ] filter data as directed
- [ ] rename columns as directed
- [ ] rename values to make data more analyzable
- [ ] handle missing values in at least two ways
- [ ] transform data to tidy format


#### **prepare-level3**
  
_apply data reshaping, cleaning, and filtering manipulations reliably and correctly by assessing data as received_ 


- [ ] identify issues in a dataset and correctly implement solutions
- [ ] convert varialbe representation by changing types
- [ ] change variable representation using one hot encoding


#### **evaluate-level1**
  
_Explain and compute basic performance metrics for different data science tasks_ 


- [ ] apply at least one metric
- [ ] interpret model performance in context


#### **evaluate-level2**
  
_Apply and interpret basic model evaluation metrics to a held out test set_ 


- [ ] apply at least three performance metrics to models
- [ ] apply metrics to subsets of data
- [ ] apply disparity metrics
- [ ] interpret at least three metrics


#### **evaluate-level3**
  
_Evaluate a model with multiple metrics and cross validation_ 


- [ ] explain cross validation
- [ ] explain importance of held out test and validation data
- [ ] describe why cross vaidation is important
- [ ] idenitfy appropriate metrics for different types of modeling tasks
- [ ] use multiple metrics together to create a more complete description of a model's performance


#### **classification-level1**
  
_identify and describe what classification is, apply pre-fit classification models_ 


- [ ] describe what classification is
- [ ] describe what a dataset must look like for classifcation
- [ ] identify appliations of classifcation in the real world
- [ ] describe set up for a classification problem (tes,train)


#### **classification-level2**
  
_fit, apply, and interpret preselected classification model to a dataset_ 


- [ ] split data for training and testing
- [ ] fit a classification model
- [ ] apply a classification model to obtain predictions
- [ ] interpret the predictions of a classification model
- [ ] examine parameters of at least one fit classifier to explain how the prediction is made
- [ ] differentiate between model fitting and generating predictions
- [ ] evaluate how model parameters impact model performance


#### **classification-level3**
  
_fit and apply classification models and select appropriate classification models for different contexts_ 


- [ ] choose appropriate classifiers based on application context
- [ ] explain how at least 3 different classifiers make predictions
- [ ] evaluate how model parameters impact model performance and justify choices when tradeoffs are necessary


#### **regression-level1**
  
_identify what data that can be used for regression looks like_ 


- [ ] identify data that is/not appropriate for regression
- [ ] describe univariate linear regression
- [ ] identify appliations of regression in the real world


#### **regression-level2**
  
_fit and interpret linear regression models_ 


- [ ] split data for training and testing
- [ ] fit univariate linear regression models
- [ ] interpret linear regression models
- [ ] fit multivariate linear regression models


#### **regression-level3**
  
_fit and explain regrularized or nonlinear regression_ 


- [ ] fit nonlinear or regrularized regression models
- [ ] interpret and explain nonlinear or regrularized regresion models


#### **clustering-level1**
  
_describe what clustering is_ 


- [ ] differentiate clustering from classification and regression
- [ ] identify appliations of clustering in the real world


#### **clustering-level2**
  
_apply basic clustering_ 


- [ ] fit Kmeans
- [ ] interpret kmeans
- [ ] evaluate clustering models


#### **clustering-level3**
  
_apply multiple clustering techniques, and interpret results_ 


- [ ] apply at least two clustering techniques
- [ ] explain the differences between two clustering models


#### **optimize-level1**
  
_Identify when model parameters need to be optimized_ 


- [ ] identify when parameters might impact model performance


#### **optimize-level2**
  
_Optimize basic model parameters such as model order_ 


- [ ] automatically optimize multiple parameters
- [ ] evaluate potential tradeoffs
- [ ] interpret optimization results in context


#### **optimize-level3**
  
_Select optimal parameters based of mutiple quanttiateve criteria and automate parameter tuning_ 


- [ ] optimize models based on multiple metrics
- [ ] describe when one model vs another is most appropriate


#### **compare-level1**
  
_Qualitatively compare model classes_ 


- [ ] compare models within the same task on complexity


#### **compare-level2**
  
_Compare model classes in specific terms and fit models in terms of traditional model performance metrics_ 


- [ ] compare models in multiple terms
- [ ] interpret cross model comparisons in context


#### **compare-level3**
  
_Evaluate tradeoffs between different model comparison types_ 


- [ ] compare models on multiple criteria
- [ ] compare optimized models
- [ ] jointly interpret optimization result and compare models
- [ ] compare models on quanttiateve and qualitative measures


#### **representation-level1**
  
_Identify options for representing text and categorical data in many contexts_ 


- [ ] describe the basic goals for changing the representation of data


#### **representation-level2**
  
_Apply at least one representation to transform unstructured  or inappropriately data for model fitting or summarizing_ 


- [ ] transform text or image data for use with ML


#### **representation-level3**
  
_apply transformations in different contexts OR  compare and contrast multiple representations a single type of data in terms of model performance_ 


- [ ] transform both text and image data for use in ml
- [ ] evaluate the impact of representation on model performance


#### **workflow-level1**
  
_Solve well strucutred fully specified problems with a single tool pipeline_ 


- [ ] pseudocode out the steps to answer basic data science questions


#### **workflow-level2**
  
_Solve well-strucutred, open-ended problems, apply common structure to learn new features of standard tools_ 


- [ ] plan and execute answering real questions to an open ended question
- [ ] describe the necessary steps and tools


#### **workflow-level3**
  
_Independently scope and solve realistic data science problems OR independently learn releated tools  and describe strengths and weakensses of common tools_ 


- [ ] scope and solve realistic data science problems
- [ ] compare different data science tool stacks
