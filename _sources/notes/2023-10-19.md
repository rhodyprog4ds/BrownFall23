---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.15.1
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Understanding Classification

Today we are going to work on understandign what happens when a classifier makes 

```{important}
You can provide [feedback on the course so far](https://forms.gle/kggc63ASy4RWPp487)
```

```{code-cell} ipython3
import pandas as pd
import seaborn as sns
from sklearn import tree
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
sns.set_theme(palette='colorblind') # this improves contrast

from sklearn.metrics import confusion_matrix, classification_report
```


Our goal is to predict the species from the measurements. Set up the problem by putting the variables in the correct roles (features and target) so that train test split will work.
```{code-cell} ipython3
iris_df = sns.load_dataset('iris')
```

Today we will use a different random state, recall that the `random_state` is like a name for the sequence of psuedo random numbers that it will use. 


```{code-cell} ipython3
# dataset vars:
# 'petal_width',  'sepal_length','species', 'sepal_width','petal_length',
feature_vars = ['petal_width',  'sepal_length', 'sepal_width','petal_length']
target_var = 'species'
X_train, X_test, y_train, y_test = train_test_split(iris_df[feature_vars],
                                                    iris_df[target_var],random_state=3)
```

Again, we will plot the data with the target as the colors

```{code-cell} ipython3
sns.pairplot(data = iris_df, hue='species')
```

We notice that this data meets the  assumptions of our model: 
- it is separable (for all classification)
- the classes are each one blob that is roughly a circle or oval (gaussian)
- the ovals are not too 
- 
```{code-cell} ipython3
gnb = GaussianNB()
```

```{code-cell} ipython3
gnb.fit(X_train,y_train)
```

```{code-cell} ipython3
y_pred = gnb.predict(X_test)
```

```{code-cell} ipython3
gnb.score(X_test,y_test)
```

We can also get a report with a few metrics.

- Recall is the percent of each species that were predicted correctly.
- Precision is the percent of the ones predicted to be in a species that are truly that species.
- the F1 score is combination of the two

```{code-cell} ipython3
print(classification_report(y_test,y_pred))
```

```{code-cell} ipython3
y_test.value_counts()
```

```{code-cell} ipython3
confusion_matrix(y_test,y_pred)
```

```{code-cell} ipython3
gnb.__dict__
```

```{code-cell} ipython3
import numpy as np
```


## What does a generative model mean? 


To do this, we extract the mean and variance parameters from the model
(`gnb.theta_,gnb.sigma_`) and `zip` them together to create an iterable object
that in each iteration returns one value from each list (`for th, sig in zip(gnb.theta_,gnb.sigma_)`).
We do this inside of a list comprehension and for each `th,sig` where `th` is
from `gnb.theta_` and `sig` is from `gnb.sigma_` we use `np.random.multivariate_normal`
to get 20 samples. In a general [multivariate normal distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) the second parameter is actually a covariance
matrix.  This describes both the variance of each individual feature and the
correlation of the features.  Since Naive Bayes is Naive it assumes the features
are independent or have 0 correlation.  So, to create the matrix from the vector
of variances we multiply by `np.eye(4)` which is the identity matrix or a matrix
with 1 on the diagonal and 0 elsewhere. Finally we stack the groups for each
species together with `np.concatenate` (like `pd.concat` but works on numpy objects
  and `np.random.multivariate_normal` returns numpy arrays not data frames) and put all of that in a
DataFrame using the feature names as the columns.

Then we add a species column, by repeating each species 20 times
`[c]*N for c in gnb.classes_` and then unpack that into a single list instead of
as list of lists.  



```{code-cell} ipython3
N = 50
gnb_df = pd.DataFrame(np.concatenate([np.random.multivariate_normal(th, sig*np.eye(4),N)
                 for th, sig in zip(gnb.theta_,gnb.var_)]),
                 columns = gnb.feature_names_in_)
gnb_df['species'] = [ci for cl in [[c]*N for c in gnb.classes_] for ci in cl]
sns.pairplot(data =gnb_df, hue='species')
```

## How does it make the predictions? 

```{code-cell} ipython3
gnb.predict_proba(X_test)
```

```{code-cell} ipython3
# make the probabilities into a dataframe labeled with classes & make the index a separate column
prob_df = pd.DataFrame(data = gnb.predict_proba(X_test), columns = gnb.classes_ ).reset_index()
# add the predictions
prob_df['predicted_species'] = y_pred
prob_df['true_species'] = y_test.values
# for plotting, make a column that combines the index & prediction
pred_text = lambda r: str( r['index']) + ',' + r['predicted_species']
prob_df['i,pred'] = prob_df.apply(pred_text,axis=1)
# same for ground truth
true_text = lambda r: str( r['index']) + ',' + r['true_species']
prob_df['correct'] = prob_df['predicted_species'] == prob_df['true_species']
# a dd a column for which are correct
prob_df['i,true'] = prob_df.apply(true_text,axis=1)
prob_df_melted = prob_df.melt(id_vars =[ 'index', 'predicted_species','true_species','i,pred','i,true','correct'],value_vars = gnb.classes_,
                             var_name = target_var, value_name = 'probability')
prob_df_melted.head()
```

```{code-cell} ipython3
# plot a bar graph for each point labeled with the prediction
sns.catplot(data =prob_df_melted, x = 'species', y='probability' ,col ='i,true',
            col_wrap=5,kind='bar')
```

## What if the assumptions are not met? 



Using a toy dataset here shows an easy to see challenge for the classifier that we have seen so far.  Real datasets will be hard in different ways, and since they're higher dimensional, it's harder to visualize the cause.
```{code-cell} ipython3
corner_data = 'https://raw.githubusercontent.com/rhodyprog4ds/06-naive-bayes/f425ba121cc0c4dd8bcaa7ebb2ff0b40b0b03bff/data/dataset6.csv'
df6= pd.read_csv(corner_data,usecols=[1,2,3])
```

```{code-cell} ipython3
df6.head(1)
```

```{code-cell} ipython3
sns.pairplot(data=df6, hue='char', hue_order=['A','B'])
```
As we can see in this dataset, these classes are quite separated.


```{code-cell} ipython3
X_train, X_test, y_train, y_test = train_test_split(df6[['x0','x1']],df6['char'], random_state=4)
```

```{code-cell} ipython3
gnb_corners = GaussianNB()
gnb_corners.fit(X_train,y_train)
gnb_corners.score(X_test, y_test)
```

But we do not get a very good classification score.

To see why, we can look at what it learned.


```{code-cell} ipython3
N = 100
gnb_df = pd.DataFrame(np.concatenate([np.random.multivariate_normal(th, sig*np.eye(2),N)
         for th, sig in zip(gnb_corners.theta_,gnb_corners.var_)]),
         columns = ['x0','x1'])
gnb_df['char'] = [ci for cl in [[c]*N for c in gnb_corners.classes_] for ci in cl]

sns.pairplot(data =gnb_df, hue='char',hue_order=['A','B'])
```

```{code-cell} ipython3
df6_pred = X_test.copy()
df6_pred['pred'] = gnb_corners.predict(X_test)
```

```{code-cell} ipython3
sns.pairplot(data =df6_pred, hue ='pred', hue_order =['A','B'])
```

This does not look much like the data and it's hard to tell which is higher at any given point in the 2D space.  We know though, that it has missed the mark. We can also look at the actual predictions.

If you try this again, split, fit, plot, it will learn different decisions, but always at least about 25% of the data will have to be classified incorrectly.


### Decision Trees

This data does not fit the assumptions of the Niave Bayes model, but a decision tree has a different rule. It can be more complex, but for the scikit learn one relies on splitting the data at a series of points along one axis at a time.  

It is a **discriminative** model, because it describes how to discriminate (in the sense of differentiate) between the classes. This is in contrast to the **generative** model that describes how the data is distributed.  

```{code-cell} ipython3
dt = tree.DecisionTreeClassifier()
```

```{code-cell} ipython3
dt.fit(X_train,y_train)
```

```{code-cell} ipython3
dt.score(X_test,y_test)
```

The sklearn estimator objects (that corresond to different models) all have the same API, so the `fit`, `predict`, and `score` methods are the same as above. We will see this also in regression and clustering.  What each method does in terms of the specific calculations will vary depending on the model, but they're always there.  

the `tree` module also allows you to plot the tree to examine it.

```{code-cell} ipython3
plt.figure(figsize=(15,20))
tree.plot_tree(dt, rounded =True, class_names = ['A','B'],
      proportion=True, filled =True, impurity=False,fontsize=10);
```

On the iris dataset, the [sklearn docs include a diagram showing the decision boundary](https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html) You should be able to modify this for another classifier.

## Setting Classifier Parameters

The decision tree we had above has a lot more layers than we would expect.  This is really simple data so we still got perfect classification. However, the more complex the model, the more risk that it will learn something noisy about the training data that doesn't hold up in the test set.  

Fortunately, we can control the parameters to make it find a simpler decision boundary.


```
dt2 = tree.DecisionTreeClassifier(max_depth=2)
dt2.fit(X_train,y_train)
dt2.score(X_test,y_test)
```

```
plt.figure(figsize=(15,20))
tree.plot_tree(dt2, rounded =True, class_names = ['A','B'],
      proportion=True, filled =True, impurity=False,fontsize=10);
```

We can compute other metrics from the confusion matrix:
- [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)
- [wiki](https://en.wikipedia.org/wiki/Confusion_matrix)

```{code-cell} ipython3

```

## Questions After Class

### When should you start focusing on portfolio check 2? 

When you get P1 feedback

### when will p1 check be graded?

As soon as possible. 


### why not use a decision tree initially for the iris dataset?

To teach the Gaussian Naive Bayes classifier, because learning different types of classifiers helps you understand the concept better. 

### Are there any popular machine learning models that use decision trees?

Yes, a lot of medical appilcations do, because since they are easy to understand, it is easier for healthcare providers to trust them. 


### Do predictive algorithms have pros and cons? Or is there a standard?

Each algorithm has different properties and strengths and weaknesses.  Some are more popular than others, but they all do have weaknesses. 

### Different kinds of trees/charts, analyze what they mean and how to translate those

### is it possible after training the model to add more data to it ?

The models we will see in class, no.  However, there is a thing called "online learning" that involves getting more data on a regular basis to improve its performance.  
