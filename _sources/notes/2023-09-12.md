---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.15.1
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---


# Iterables and Pandas Data Frames


## House Keeping

### Grading is not done, 

you will get a notificaiton when yours is

### Closing Jupyter server.

In the terminal use Ctrl+C (actually control, not command on mac).

It will ask you a question and give options, read and follow 

**or**

do ctrl+C a second time. 

A jupyter server typically runs at `localhost:8888`, but if you have multiple servers running the count increases. 


Once I saw a student in office hours working on `localhost:8894` asking why their code kept crashing.

```{important}
Remember to close your jupyter server
```


+++

## Grading solution

```{code-cell} ipython3
def compute_grade(num_level1,num_level2,num_level3):
    '''
    Computes a grade for CSC/DSP310 from numbers of achievements at each level

    Parameters:
    -----------

    num_level1 : int
      number of level 1 achievements earned
    num_level2 : int
      number of level 2 achievements earned
    num_level3 : int
      number of level 3 achievements earned

    Returns:
    --------
    letter_grade : string
      letter grade with modifier (+/-)
    '''
    if num_level1 == 15:
        if num_level2 == 15:
            if num_level3 == 15:
                grade = 'A'
            elif num_level3 >= 10:
                grade = 'A-'
            elif num_level3 >=5:
                grade = 'B+'
            else:
                grade = 'B'
        elif num_level2 >=10:
            grade = 'B-'
        elif num_level2 >=5:
            grade = 'C+'
        else:
            grade = 'C'
    elif num_level1 >= 10:
        grade = 'C-'
    elif num_level1 >= 5:
        grade = 'D+'
    elif num_level1 >=3:
        grade = 'D'
    else:
        grade = 'F'


    return grade
```
When we run the cell above that adds the function to memory.  

Now that it is run, jupyter can show us `compute_grade` as an option when we tab complete after typing the first few letters.  
 
When we restarted the kernel, we saw that before running the cell above, the tab complete did not work.  

```{important}
this is important to understand what works when and why so that you know what to expect and can get unstuck
```

```{code-cell} ipython3
compute_grade(15,15,14)
```

```{code-cell} ipython3
assert compute_grade(15,15,15) =='A'
```

`asssert` succeeds quietly

```{code-cell} ipython3
assert compute_grade(15,15,15) =='B'
```
but fails with a specific error

````{margin}
```{note}
In class we used the shift + tab to get help, but so that it displays in the notes, I'm using the built-in help function
```
````
The docstring is important, because it is the help. 

```{code-cell} ipython3
help(compute_grade)
```
+++


##  Everything is Data



Data we will see: 

- tabular data
- websites as data
- activity logs on websites
- images
- text 


## Why inspection in code?

Some IDEs give you GUI based tools to inspect objects.  We are going to do it programmatically inline with our analyses for two reasons.

- (minor, logistical) it helps make for good notes
- (most importantly) it helps build habits of data science

In data science, our code will be aiming to tell a story.


+++

If you're curious about something, try it out, see what happens.  We're going to use a lot of code inspection tools during class.  These are helpful both for understanding what's going on, but the advantage to knowing how to get this information programmatically even though a different IDE would give you inspection tools  is that it helps you treat your code as data.

## everything is an object

let's examine the `type` of some variables:
```{code-cell} ipython3
a = 4
b ='monday'
c = 5.3
d =print
```

```{code-cell} ipython3
type(a)
```
ints are a base python type, like they appear in other languages


strings are iterable type, meaning that theycan be indexed into, or their elements iterated over.  For a more technical definition, see the [official python glossary entry](https://docs.python.org/3/glossary.html#term-iterable)
```{code-cell} ipython3
type(b)
```

we can select one element
```{code-cell} ipython3
b[0]
```

or multiple, this is called slicing. 

```{code-cell} ipython3
b[0:3]
```


negative numbers count from the right. 
```{code-cell} ipython3
b[-1]
```

decimals defualt to float
```{code-cell} ipython3
type(c)
```

a variable can hold a whole function. 
```{code-cell} ipython3
type(d)
```

functions are also objects like any other type in python

we can use the variable just like the function itself

```{code-cell} ipython3
d('hello')
```

```{code-cell} ipython3
print('hello')
```


## Tabular Data 

Structured data is easier to work with than other data.

We're going to focus on tabular data for now. At the end of the course, we'll examine images, which are structured, but more complex and text, which is much less structured.

+++
## Getting familiar with the datset

We're going to use a dataset about [coffee quality](https://github.com/jldbc/coffee-quality-database/) today.



How was this dataset collected?
- reviews added to DB
- then scraped

Where did it come from?
- coffee Quality Institute's trained reviewers.

what format is it provided in?
- csv (Comma Separated Values)

what other information is in this repository?
- the code to scrape and clean the data
- the data before cleaning


It's important to always know where data came from and how it was collected.

This helps you know what is is useful for and what its limitations are.

```{admonition} Further Reading
An important research article on documenting datasets for machine learning is called [Datasheets for Datasets](https://www.microsoft.com/en-us/research/publication/datasheets-for-datasets/) these researchers also did a [follow up study](https://www.microsoft.com/en-us/research/publication/understanding-machine-learning-practitioners-data-documentation-perceptions-needs-challenges-and-desiderata/) to better understand how practitioner use datasheets and decide how to use data.

If topics like this are interesting to you, let me know! my research is related to this and I have a lot of students who complete 310 do research in my lab. 
```

## Loading data


Get raw url for the dataset click on the raw button on the [csv page](https://github.com/jldbc/coffee-quality-database/blob/master/data/robusta_ratings_raw.csv), then copy the url.

```{code-cell} ipython3
coffee_data_url = 'https://raw.githubusercontent.com/jldbc/coffee-quality-database/master/data/robusta_data_cleaned.csv'
```

We will use data with a library called pandas.  By convention, we import it like:
```{code-cell} ipython3
import pandas as pd
```

- the `import` keyword is used for loading packages
- `pandas` is the name of the package that is installed
- `as` keyword allows us to assign an alias (nickname)
- `pd` is the typical alias for pandas
  

we will load the data with `pd.read_csv()`

```{code-cell} ipython3
pd.read_csv(coffee_data_url)
```

This read in the data and printed it out because it is the last line on the cell.
If we do something else after, it will read it in, but not print it out.

In order to use it, we save the output to a variable.

```{code-cell} ipython3
coffee_df = pd.read_csv(coffee_data_url)
```

we can look at it again using the jupyter display
```{code-cell} ipython3
coffee_df
```

Next we examine the type

```{code-cell} ipython3
type(coffee_df)
```

This is a new type provided by the `pandas` library, called a [dataframe](https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe)

We can also exmaine its parts.  It consists of several; first the column headings

```{code-cell} ipython3
coffee_df.columns
```

These are a special type called [Index](https://pandas.pydata.org/docs/reference/api/pandas.Index.html) that is also provided by pandas. 

It also tells us that the actual headings are of `dtype` `object`. `object` is used for strings or columns with [mixed types](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html)

the [`dtype`](https://pandas.pydata.org/docs/user_guide/basics.html#dtypes) is slightly different from base Python types and is how pandas classifies but roughly is the same idea as a type. 

```{code-cell} ipython3
type(coffee_df.columns)
```

It also has an index (first column, visually) but it is special because this is how you can index the data.

```{code-cell} ipython3
coffee_df.index
```

Right now this is an autogenerated index, but we can also use the `index_col` parameter to set that up front.

```{code-cell} ipython3
coffee_df = pd.read_csv(coffee_data_url,index_col=0)
coffee_df
```


```{code-cell} ipython3
coffee_df.index
```
Now we see that it uses the actual first column as the index that is bolded. 

We can look at the first 5 rows with `head`
```{code-cell} ipython3
coffee_df.head()
```

```{admonition} Try it yourself
How can you look at the first 3 or last 2 rows?
```

and the last 5 with `tail`
```{code-cell} ipython3
coffee_df.tail()
```

```{important}
We did not do this step in class
```

the shape of a DataFrame is an attribute
```{code-cell} ipython3
coffee_df.shape
```


We can pick out columns by name.

```{code-cell} ipython3
coffee_df['Color']
```
a single column is a new type, called Series

```{code-cell} ipython3
type(coffee_df['Color'])
```

We can pick out rows using the `loc` accessor.  It is a tricky concept because it is **indexing** so it uses square brackets `[]` but it uses a `.` like a method.  This is a sort of atypical syntax, but we do not use it very often.  We pick out single columns a lot, so that has a nice easy syntax like above, but this is rare, so it got the less elegant syntax. 

```{code-cell} ipython3
coffee_df.loc[1]
```

We can also slice in dataframes, just like in strings. 

```{code-cell} ipython3
subset_df = coffee_df.loc[5:8]
subset_df
```

Now `loc[1]` will give a key error because there is no `1` in the index. 
```{code-cell} ipython3
subset_df.loc[1]
```

the only values that will work in `loc` are the ones in the index: 
```{code-cell} ipython3
subset_df.index
```

however, with `iloc` they are indexed by integer values starting with 0. 
```{code-cell} ipython3
subset_df.iloc[1]
```


## Questions After Class


### I think this something I need to figure but how do the localhost or just utilizing a url in VS Code? I was late to the class, I never got how to do the jupyter lab thing.

For this class, you need to use jupyter notebooks without extraneous metadata.  If you use jupyter inside of vs code, it adds extraneous metadata that makes it hard to grade and VS code, in my experience, does not provide the most helpful autocomplete for Data Science.

Please see office hours to get help with it. 

### Is the Python we use in Jupyter lab notebooks any different from traditional Python?

the Python is mostly all the same.  There are different python interpreters that have some slightly different behaviors, but mostly only in the display.  As a matter of technicality, jupyter uses the [ipython](https://ipython.org/documentation.html) python as the kernel. 

### Does index just list all the rows?

the index is the *name* of the rows the same way that the column headers are the *name* of the columns.

### How you copied the file url from github.

Click the [raw button](https://docs.github.com/en/repositories/working-with-files/using-files/viewing-a-file#viewing-or-copying-the-raw-file-content) and then copy the URL from your browswer's url bar. 

### How did we change the index?

we changed the index from the inferred (figured out by pandas) `RangeIndex` to a column of the data by adding the `index_col=0` parameter  to our `read_csv` call.


### I would like to learn more about the panda commands

We will continue learning more pandas features for the next few weeks. 

### are we gonna have to use what we learned today in a bigger program in the future 

Yes, these features we used today are the basis of all of the data analysis we will do all semester.  However, we will not be writing "programs" the way you may have for other classes, we will be doing data analyses, which are more narrative.

### How can I use Jupyter to clean data?

jupyter is a way to work with python code.  We will learn what clean data looks like and more ways to manipulate dataframes to make it clean in two weeks. 


### Why is taking data from columns much more common than taking it from rows? 

We set our data up so that each column is a varible.  We often want to treat different variables differently, but do the same thing to all of the rows. 

### I was wondering more about the Index variable type and was also curious as to what that could be used for.

the `Index` type from `pandas` is a component of a `DataFrame`, we will use them implicitly whenever we work with a part of a dataframe and explicitly when we clean data. 

### I know by convention we use the typical alias for importing libraries, but is it okay to use our own alias for our own private programs?

using nonstandard aliases is a bad habit to develop and I cannot endorse it. Technically the code will run, but in class it will be a style violation. 

### does the panda's data start indexing at 1 because 0 is where the table headers are located?

Indexing using `loc` started at 1 because the dataset had 1 there, in the second example it started at 5.  

using `iloc` starts at 0. 

### In the dataset we loaded, I noticed that there were some zeros, which are nulls, I'm guessing we have to clean those out, and I was wondering how?

zeros are a value, nulls are encoded in different ways.  We will learn how to deal will missing values in two weeks. 

### How often do data sets need to be cleaned/manipulated before proper analysis can be done?

Real data, will almost alwasy need to be fixed a little bit. 

### how does being able to view specific rows/columns help us make conclusions about data?

For example, maybe one column is the thing you are interested in, you may want to know on stats on the one column. 


### Are assignments always a certain level or can one assignment be done to be a level 1 or a level 2 assignment

Going forward, Assignments are always targeted at level 2. In class prismia questions will assess at level 1.  An incomplete attempt at an assignment might be evaluated only at level 1, so that can be a way to make up for missed class and then you earn the level 2 in the next assignment that assess that skill. 

### will I be able to use data from an existing lab that I work in for certain assignment?

Yes, as long as the data is allowed to be shared.  Please confirm with your PI. 

### When we submit to GitHub, do we need to do anything other than upload the file?

For your portfolio, no.  For other assignments, there will be a step to do, and there will be instructions in the assignment. 

### Are we going to have to create our own datasets for any future assignments rather than downloading datasets form the Internet?

Assignment 2 you will build a dataset about datasets, but other than that you will mostly use datasets that you find online or that you have for another purpose. 

### How to better navigate github and not second guess my posts there

```{warning}
this will be added later. 
```
